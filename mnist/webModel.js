
class Layer {
    constructor(numNeurons, numInputs, activation = 'sigmoid') {
        this.numNeurons = numNeurons;
        this.numInputs = numInputs;
        this.activation = activation;

        this.weights = this.generateRandomMatrix(this.numNeurons, this.numInputs);
        this.biases = new Array(this.numNeurons).fill(0);

        this.input = new Array(this.numNeurons).fill(0);
        this.z = new Array(this.numNeurons).fill(0);
        this.output = new Array(this.numNeurons).fill(0);
        this.error = new Array(this.numNeurons).fill(0);
        this.delta = new Array(this.numNeurons).fill(0);
    }

    generateRandomMatrix(row, col) {
        return Array.from({ length: row }, () =>
            Array.from({ length: col }, () => Math.random() * Math.sqrt(2 / this.numInputs)
            ));
    }

    activate(x) {
        if (this.activation === 'sigmoid') return 1 / (1 + Math.exp(-x));
        if (this.activation === 'relu') return Math.max(0, x);
    }

    activationDerivative(x) {
        if (this.activation === 'sigmoid') return x * (1 - x); // x = sigmoid(x)
        if (this.activation === 'relu') return x > 0 ? 1 : 0;
    }

    softmax(x) {
        const maxX = Math.max(...x);
        const expValues = x.map(value => Math.exp(value - maxX));
        const sumExpValues = expValues.reduce((a, b) => a + b, 0);
        return expValues.map(value => value / sumExpValues);
    }

    forward(input) {
        this.input = [...input];
        for (let i = 0; i < this.numNeurons; i++) {
            this.z[i] = this.biases[i];
            for (let j = 0; j < this.numInputs; j++) {
                this.z[i] += this.weights[i][j] * this.input[j];
            }
            // this.output[i] = this.activate(this.z[i]);
        }
        if (this.activation == 'softmax') {
            this.output = this.softmax(this.z);
        } else {
            for (let i = 0; i < this.numNeurons; i++) {
                this.output[i] = this.activate(this.z[i]);
            }
        }
        return this.output;
    }

    // rm
    backward(nextLayer) {
        for (let i = 0; i < this.numNeurons; i++) {
            this.error[i] = 0;
            for (let j = 0; j < nextLayer.numNeurons; j++) {
                this.error[i] += nextLayer.delta[j] * nextLayer.weights[j][i];
            }

            if (this.activation == 'relu')
                this.delta[i] = this.error[i] * this.activationDerivative(this.z[i]);
            else
                this.delta[i] = this.error[i] * this.activationDerivative(this.output[i]);
        }
    }

    // rm
    updateWB(learningRate) {
        for (let i = 0; i < this.numNeurons; i++) {
            for (let j = 0; j < this.numInputs; j++) {
                this.weights[i][j] -= learningRate * this.delta[i] * this.input[j];
            }
            this.biases[i] -= learningRate * this.delta[i];
        }
    }
}

class NeuralNetwork {
    constructor(layerSizes, learningRate, epochs) {
        this.numLayers = layerSizes.length - 1;
        this.layers = [];
        let i = 1;
        for (i; i < layerSizes.length - 1; i++) {
            this.layers.push(new Layer(layerSizes[i], layerSizes[i - 1], 'relu'));
        }
        this.layers.push(new Layer(layerSizes[i], layerSizes[i - 1], 'softmax'));

        this.learningRate = learningRate;
        this.epochs = epochs;

        this.totalError = 0.0;
    }

    forwardPass(inputArr) {
        let dataInput = inputArr;
        for (let i = 0; i < this.numLayers; i++) {
            dataInput = this.layers[i].forward(dataInput);
        }
        // at the last iteration dataInput accepts the
        // forward pass' final output generated by output layer
        return dataInput;
    }

    // rm
    backwardPass(labelArr) {
        // find err for the last layer (-1)th
        let nextLayer = this.layers[this.numLayers - 1];
        // console.log(nextLayer);
        for (let i = 0; i < nextLayer.numNeurons; i++) {
            // // MSE + sigmoid
            // nextLayer.error[i] = nextLayer.output[i] - labelArr[i];
            // nextLayer.delta[i] = nextLayer.error[i] * nextLayer.activationDerivative(nextLayer.output[i]);

            // softmax + cross-entropy derivative
            nextLayer.delta[i] = nextLayer.output[i] - labelArr[i];
            nextLayer.error[i] = nextLayer.delta[i];

            this.totalError -= labelArr[i] * Math.log(nextLayer.output[i] + 1e-9);
        }

        for (let i = this.numLayers - 2; i >= 0; i--) {
            const currLayer = this.layers[i];
            currLayer.backward(nextLayer);
            nextLayer = currLayer;
        }
    }

    // rm
    updateWB() {
        for (let i = this.numLayers - 1; i >= 0; i--) {
            const currLayer = this.layers[i];
            currLayer.updateWB(this.learningRate);
        }
    }

    // rm
    shuffleData(DATA, NUM_SAMPLES) {
        // randomize inputs for batch making
        // is optional but improves generalization (yes)
        function swap(arr1, arr2, i, rand) {
            [arr1[i], arr1[rand]] = [arr1[rand], arr1[i]];
            [arr2[i], arr2[rand]] = [arr2[rand], arr2[i]];
        }

        for (let i = 0; i < NUM_SAMPLES; i++) {
            const rand = parseInt(Math.random() * NUM_SAMPLES) % NUM_SAMPLES;
            swap(DATA.inputs, DATA.labels, i, rand);
        }
    }

    // rm
    trainSGD(TRAINING_DATA) {
        const NUM_SAMPLES = Math.min(TRAINING_DATA.inputs.length, TRAINING_DATA.labels.length);
        for (let epoch = 0; epoch < this.epochs; epoch++) {
            this.shuffleData(TRAINING_DATA, NUM_SAMPLES);
            for (let s = 0; s < NUM_SAMPLES; s++) {
                this.forwardPass(TRAINING_DATA.inputs[s]);
                this.backwardPass(TRAINING_DATA.labels[s]);
                this.updateWB();
            }
            console.log(`| Epoch ${String(epoch).padStart(4, '0')} | Error: ${(this.totalError / NUM_SAMPLES).toFixed(3)} |`);

            // if (epoch % 100 == 0) {
            // console.log(`| Epoch ${String(epoch).padStart(4, '0')} | Error: ${(this.totalError / NUM_SAMPLES).toFixed(3)} |`);
            // this.learningRate *= 0.95; // decay LR per 1000 Epochs
            // }

            this.totalError = 0.0;
        }
    }

    // rm
    // accumulateWBbatch(inputArr, Ho, Hd, Od, batchGradients) {
    //     // --- Accumulate weights and biases ---
    //     for (let i = 0; i < this.NUM_OUTPUTS; i++) {
    //         for (let j = 0; j < this.NUM_HIDDEN; j++) {
    //             batchGradients.Wo[i][j] += Od[i] * Ho[j];
    //         }
    //     }
    //     for (let i = 0; i < this.NUM_OUTPUTS; i++) {
    //         batchGradients.Bo[i] += Od[i];
    //     }

    //     for (let i = 0; i < this.NUM_HIDDEN; i++) {
    //         for (let j = 0; j < this.NUM_INPUTS; j++) {
    //             batchGradients.Wh[i][j] += Hd[i] * inputArr[j];
    //         }
    //     }
    //     for (let i = 0; i < this.NUM_HIDDEN; i++) {
    //         batchGradients.Bh[i] += Hd[i];
    //     }
    //     // --- Accumulate weights and biases ---
    // }

    // updateWBbatch(batchGradients, batchLen) {
    //     // W -= (learning_rate / batchLen) * gradient_sum_W
    //     // B -= (learning_rate / batchLen) * gradient_sum_B
    //     // --- Update weights and biases ---
    //     for (let i = 0; i < this.NUM_OUTPUTS; i++) {
    //         for (let j = 0; j < this.NUM_HIDDEN; j++) {
    //             this.Wo[i][j] -= (this.LEARNING_RATE / batchLen) * batchGradients.Wo[i][j];
    //         }
    //         this.Bo[i] -= (this.LEARNING_RATE / batchLen) * batchGradients.Bo[i];
    //     }

    //     for (let i = 0; i < this.NUM_HIDDEN; i++) {
    //         for (let j = 0; j < this.NUM_INPUTS; j++) {
    //             this.Wh[i][j] -= (this.LEARNING_RATE / batchLen) * batchGradients.Wh[i][j];
    //         }
    //         this.Bh[i] -= (this.LEARNING_RATE / batchLen) * batchGradients.Bh[i];
    //     }
    //     // --- Update weights and biases ---
    // }

    // trainMBGD(TRAINING_DATA, BATCH_SIZE) {
    //     const NUM_SAMPLES = Math.min(TRAINING_DATA.inputs.length, TRAINING_DATA.labels.length);
    //     for (let epoch = 0; epoch < this.EPOCHS; epoch++) {
    //         this.shuffleData(TRAINING_DATA, NUM_SAMPLES);

    //         for (let batchStart = 0; batchStart < NUM_SAMPLES; batchStart += BATCH_SIZE) {
    //             const batchEnd = Math.min(batchStart + BATCH_SIZE, NUM_SAMPLES);
    //             // --- singular batch start ---
    //             let batchGradients = {
    //                 Wh: this.generateZeroMatrix(this.NUM_HIDDEN, this.NUM_INPUTS),
    //                 Bh: new Array(this.NUM_HIDDEN).fill(0),
    //                 Wo: this.generateZeroMatrix(this.NUM_OUTPUTS, this.NUM_HIDDEN),
    //                 Bo: new Array(this.NUM_OUTPUTS).fill(0)
    //             };

    //             for (let s = batchStart; s < batchEnd; s++) {
    //                 // --- singular input start ---
    //                 const Ho = new Array(this.NUM_HIDDEN).fill(0);
    //                 const He = new Array(this.NUM_HIDDEN).fill(0);
    //                 const Hd = new Array(this.NUM_HIDDEN).fill(0);

    //                 const Oo = new Array(this.NUM_OUTPUTS).fill(0);
    //                 const Oe = new Array(this.NUM_OUTPUTS).fill(0);
    //                 const Od = new Array(this.NUM_OUTPUTS).fill(0);

    //                 this.forwardPass(TRAINING_DATA.inputs[s], Ho, Oo);
    //                 this.backwardPass(TRAINING_DATA.labels[s], Ho, He, Hd, Oo, Oe, Od);
    //                 this.accumulateWBbatch(TRAINING_DATA.inputs[s], Ho, Hd, Od, batchGradients);
    //                 // --- singular input end ---
    //             }
    //             const batchLen = batchEnd - batchStart;
    //             // --- update batch gradients here ---
    //             this.updateWBbatch(batchGradients, batchLen);
    //             // --- update batch gradients here ---

    //             // --- singular batch end ---
    //             // batchStart += BATCH_SIZE;
    //             // batchEnd += BATCH_SIZE;
    //             // batchEnd = Math.min(batchEnd, NUM_SAMPLES);
    //         }

    //         console.log(`| Epoch ${String(epoch).padStart(4, '0')} | Error: ${(this.totalError / NUM_SAMPLES).toFixed(3)} |`);
    //         this.totalError = 0.0;

    //         // if (epoch % 1000 == 0) {
    //         //     console.log(`| Epoch ${String(epoch).padStart(4, '0')} | Error: ${(this.totalError / NUM_SAMPLES).toFixed(3)} |`);
    //         // }
    //         // this.totalError = 0.0;
    //     }
    // }

    predict(inputArr) {
        return this.forwardPass(inputArr);
    }

    // rm
    evaluate(TESING_DATA) {
        let correct = 0;
        let totalTestSize = Math.min(TESING_DATA.inputs.length, TESING_DATA.labels.length);

        for (let i = 0; i < totalTestSize; i++) {
            const inputArr = TESING_DATA.inputs[i];
            const labelArr = TESING_DATA.labels[i];
            const prediction = this.predict(inputArr);
            // console.log(`| INPUT: ${inputArr} | OUTPUT: ${prediction.map(x => x.toFixed('3'))} | LABEL: ${labelArr} | ERROR: ${error} |`);
            // console.log(`| OUTPUT: ${prediction.map(x => x.toFixed('3'))} |\n| LABEL: ${labelArr} |\n| ERROR: ${error} |`);

            if (prediction.indexOf(Math.max(...prediction)) === labelArr.indexOf(Math.max(...labelArr)))
                correct++;
        }
        console.log("------- Result -------");
        console.log("Correct:  ", correct);
        console.log("Total:    ", totalTestSize);
        console.log("Accuracy: ", (correct / totalTestSize * 100).toFixed('2'), '%');
    }
}

// module.exports = NeuralNetwork;